{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3a821b9e-8823-47cd-811d-fb503a889c82",
   "metadata": {},
   "source": [
    "# visualizeKraken2 v.beta0.8\n",
    "\n",
    "2022.10.29\n",
    "\n",
    "Implemented as a class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eda12d6-8fc3-44bd-8e1a-9db918fb9c23",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import ftplib\n",
    "import zipfile\n",
    "import re\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "import pandas as pd\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fd0d053-26ef-428f-854e-ea50a0aa5933",
   "metadata": {},
   "outputs": [],
   "source": [
    "version = 'beta0.8'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "956221b1-2746-4bfd-88a0-c013c8fcd6ba",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Startup functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "164df963-474e-4d07-9cc5-cff47b37afc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def downloadDatabase(databaseFolder, databaseFileName):\n",
    "    \"\"\"\n",
    "    If the correct file is not in its local place, this function removes the whole database \n",
    "    folder and downloads everything from scratch from the NCBI server. The remove is done\n",
    "    to avoid problems with old or incomplete files from previous downloads.    \n",
    "    \"\"\"\n",
    "    start = time.time()\n",
    "    print('\\nvisualizeKraken2 v.' + version)\n",
    "    print('------------------------------\\n')\n",
    "    print('Checking for database source file...')\n",
    "    \n",
    "    if not os.path.isfile(str(databaseFolder) + '/fullnamelineage.dmp'): # this is the file used to build the database\n",
    "        if os.path.isfile(databaseFileName):\n",
    "            os.remove(databaseFileName) # this removes any old zip file that might cause problems.\n",
    "        shutil.rmtree(databaseFolder) # os module stops you because of windows admin rights.\n",
    "        os.mkdir(databaseFolder)\n",
    "        print('directory \"' + str(databaseFolder) + '\" created\\n')\n",
    "        with ftplib.FTP('ftp.ncbi.nlm.nih.gov') as ftp: # connecting to the NCBI server.\n",
    "            print('Downloading taxonomy database from NCBI...\\n')\n",
    "            print('First, a scary message from the US government:')\n",
    "            print(ftp.getwelcome()) # no idea what this means..\n",
    "            print('\\nAt least the server is ready.\\n\\nDownloading...\\n')\n",
    "            try:\n",
    "                ftp.login()\n",
    "                ftp.cwd('pub/taxonomy/new_taxdump/') # navigating to the correct directory in the server.\n",
    "                with open(databaseFileName, \"wb\") as lf:\n",
    "                    ftp.retrbinary(\"RETR \" + databaseFileName, \n",
    "                                   lf.write, 8*1024) # download in binary to prevent file corruption\n",
    "            \n",
    "            except ftplib.all_errors as error:\n",
    "                print('FTP error: ',  error)\n",
    "                print(\"This means something has gone wrong with the server. \\\n",
    "                      Make sure you're connected to the internet and try again.\")\n",
    "            \n",
    "        with zipfile.ZipFile(databaseFileName, 'r') as zipFile: # unzips file\n",
    "            zipFile.extractall(databaseFolder)\n",
    "        \n",
    "        os.remove(databaseFileName) # removes the zip file and any downloaded files which are not needed.\n",
    "        for file in os.listdir(databaseFolder):\n",
    "            if file != 'fullnamelineage.dmp':\n",
    "                #print(str(databaseFolder) + '/' + str(file) + ' removed') # can be used for troubleshooting.\n",
    "                os.remove(str(databaseFolder) + '/' + str(file))\n",
    "        print('\\nDatabase downloaded.\\n')\n",
    "        end = time.time()\n",
    "        print('Time elapsed:', str(round(end-start, 1)), 'seconds\\n')\n",
    "\n",
    "    else:\n",
    "        print('\\nDatabase source file exists already. No download required.\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7727701-cb31-434b-afe6-40ceb46d7db1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def buildDatabase(databaseFolder):\n",
    "    \"\"\"\n",
    "    Builds a python dictionary from the source file downloaded from NCBI.\n",
    "    This is the most time-consuming step in the program and so is done before any analysis is started.\n",
    "    \"\"\"\n",
    "    start = time.time()\n",
    "    dataBase = {}\n",
    "    print('Building database...\\n')\n",
    "    with open(str(databaseFolder) + '/fullnamelineage.dmp', \n",
    "              errors='ignore') as inputF: # decoding the .dmp file = problematic. Errors are now ignored. Downstream problems?\n",
    "        for line in inputF: # this can be done more elegantly\n",
    "            tempList1 = re.split(r'\\t\\|\\t', line)\n",
    "            tempList2 = re.split(r'; ', tempList1[2])\n",
    "            tempList3 = []\n",
    "            tempList3.append(tempList1[1])\n",
    "            tempList3.append(tempList2[:-1])\n",
    "            dataBase[tempList1[0]] = tempList3\n",
    "            #for key,item in dataBase.items(): # can be used for troubleshooting\n",
    "                #print(key, item)\n",
    "    \n",
    "    print('Database built.\\n')\n",
    "    print('Length of dictionary \"dataBase\":',len(dataBase))\n",
    "    end = time.time()\n",
    "    print('Time to build database:', str(round(end-start, 1)), 'seconds\\n')\n",
    "    return dataBase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c8ab9f2-9f83-4a2e-ad27-e8bbb66f753d",
   "metadata": {},
   "outputs": [],
   "source": [
    "databaseFolder = \"downloaded_NCBI_taxonomy_database\" \n",
    "# this can be changed if you prefer another folder name.\n",
    "\n",
    "databaseFileName = \"new_taxdump.zip\" \n",
    "# this is the file name on the NCBI server. Don't change. If unexplainable errors occur, check if this file's \n",
    "# name has changed on the NCBI server. It is unlikely though.\n",
    "# zip file most compatible with different systems? There are .gz varieties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04cf9587-0a58-4932-8953-52408003fbe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "downloadDatabase(databaseFolder, databaseFileName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b934d1b-f108-4927-825c-dedae1f7c61d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataBase = buildDatabase(databaseFolder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79d9bc46-4cb8-440e-886d-b901704a61c7",
   "metadata": {},
   "source": [
    "### Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcd3a3d0-74d3-4b9d-aa34-0522c6de570d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class krakView:\n",
    "    \"\"\"\n",
    "    Defines a class for visualizing and displaying data from an imported kraken2 txt file.\n",
    "    Input file must be in the same folder as the script, unless the entire path is provided.\n",
    "    \"\"\"\n",
    "    VERSION = \"Version \" + version\n",
    "    \n",
    "    def __init__ (self, krakenFile, filter = 5):\n",
    "        \"\"\"\n",
    "        Creates an object from a kraken2 txt file named according to the following pattern: filename.kraken2     \n",
    "        \"\"\"\n",
    "        self.sourceFile = krakenFile\n",
    "        self.data = np.loadtxt(krakenFile, dtype=str, delimiter='\\t')\n",
    "        self.uniqueIDs, self.count = np.unique(self.data[:,2], return_counts=True)\n",
    "        self.count = self.count[1:]\n",
    "        self.uniqueIDs= self.uniqueIDs[1:] \n",
    "        \n",
    "    def showFormat(self, n = 5):\n",
    "        \"\"\"\n",
    "        Prints the n first lines of the kraken file. Default n = 5.\n",
    "        \"\"\"\n",
    "        return self.data[0:n, :]\n",
    "    \n",
    "    def percentClassified(self, output = 1):\n",
    "        \"\"\"\n",
    "        Returns percentage of sucessfully classified fasta sequences from the kraken analysis.\n",
    "        output = 1 means a descriptive message will be displayed. Can be disabled by output = 0.\n",
    "        \"\"\"\n",
    "        Us = np.sum(np.char.count(self.data[:, 0], 'U'))\n",
    "        Cs = np.sum(np.char.count(self.data[:, 0], 'C'))\n",
    "        percentageC = float(round((Cs/(Cs+Us))*100,1))\n",
    "        if output == 1:\n",
    "            print('The percentage of classified sequences in the fasta file: ' + str(percentageC) + '%')\n",
    "        return percentageC\n",
    "    \n",
    "    def numberUniqueIDs(self, output = 1):\n",
    "        \"\"\"\n",
    "        Returns the number of unique taxonomy IDs found in the kraken file. \n",
    "        Output = 1 displays a message, output = 0 disables it.\n",
    "        This can be a guideline to what to filter by. Maybe add a range.\n",
    "        \"\"\"\n",
    "        if output == 1:\n",
    "            print('Number of unique taxIDs found: ' + str(len(self.uniqueIDs)))\n",
    "        return len(self.uniqueIDs)\n",
    "    \n",
    "    def mapIDs(self, minMatches = 5):\n",
    "        \"\"\"\n",
    "        Maps the IDs in the kraken file to the species names and ancestors in the NCBI database.\n",
    "        \n",
    "        minMatches specifies filtering by number of matches found for a specific taxon,\n",
    "        for example filter = 5 maps only the taxons with more than 5 matches in the original fasta.\n",
    "        Too many entries may cause problems with plotly visualization, so filtering by 5 or 10 is \n",
    "        recommended. \n",
    "        \n",
    "        \"root\" means that NCBI could not place it more precisely than at the root of its taxonomy tree, \n",
    "        which basically tells us nothing except that the sequence contained nucleotides. These entries are removed.\n",
    "        \n",
    "        Commented out prints can be used for troubleshooting.   \n",
    "        \"\"\"\n",
    "        speciesCounts = [] # number of matches for each ID\n",
    "        speciesNames = [] # names of the LCAs\n",
    "        speciesLineage = [] # full lineage in a list\n",
    "        for i in range(len(self.uniqueIDs)):\n",
    "            #print('\\ni=', i, '\\n')\n",
    "            if self.count[i] > minMatches: # Filter by number of matches.\n",
    "                #print('i=', i)\n",
    "                if self.uniqueIDs[i] == '1':\n",
    "                    print('\"' + str(dataBase[self.uniqueIDs[i]][0]) + '\" ' + 'with ' + \n",
    "                          str(self.count[i]) + ' counts removed from list.')\n",
    "                else:\n",
    "                    try:\n",
    "                        #print(self.dataBase[self.uniqueIDs[i]][0])\n",
    "                        speciesNames.append(dataBase[self.uniqueIDs[i]][0])\n",
    "                        reversedAncestors = list(dataBase[self.uniqueIDs[i]][1])\n",
    "                        reversedAncestors.reverse() # reversing to make parsing in ascending order easier\n",
    "                        speciesLineage.append(reversedAncestors)\n",
    "                        speciesCounts.append(self.count[i]) \n",
    "                    except:\n",
    "                        #print('i=', i)\n",
    "                        print('ID', self.uniqueIDs[i], 'not in database')\n",
    "            \n",
    "        if len(speciesCounts) == len(speciesNames) == len(speciesLineage):\n",
    "            print(len(speciesLineage), 'unique taxons found.')\n",
    "        else:\n",
    "            print('Something went horribly wrong with database mapping. Visualization will probably not work :(')\n",
    "        \n",
    "        # This next part arranges the data in the format required by plotly to produce the visualizations.\n",
    "        \n",
    "        char = [] # creates a list of characters, each character is an object in the plot\n",
    "        parent = [] # the closest parent of the enrty in char. Every object in parent must also be in char.\n",
    "        match = [] # the number of matches for the taxon in question.\n",
    "\n",
    "        listOfRootNodes = ['cellular organisms', \n",
    "                          'Viruses', \n",
    "                          'other entries', \n",
    "                          'unclassified entries']\n",
    "\n",
    "        for i in range(len(speciesNames)):\n",
    "            #print('\\n---------- entry', i,  '--------')\n",
    "            #print('Name:', speciesNames[i], '\\n')\n",
    "            #print('Lineage list:', speciesLineage[i])\n",
    "            if speciesNames[i] in listOfRootNodes:\n",
    "                char.append(speciesNames[i])\n",
    "                match.append(speciesCounts[i])        \n",
    "                parent.append('')\n",
    "                #print('i=', i, '\\nroot APPENDED as parent to', speciesNames[i], '\\n')\n",
    "            else:\n",
    "                char.append(speciesNames[i])\n",
    "                match.append(speciesCounts[i])\n",
    "                parent.append(speciesLineage[i][0])\n",
    "                #print('i=', i, speciesLineage[i][0], 'appended as PARENT to', speciesNames[i])\n",
    "                for j in range(len(speciesLineage[i])):\n",
    "                    #print('Current ancestor:', speciesLineage[i][j])\n",
    "                    if speciesLineage[i][j] not in speciesNames and speciesLineage[i][j] not in char:\n",
    "                        if speciesLineage[i][j] in listOfRootNodes:\n",
    "                            #print('i=', i)\n",
    "                            char.append(speciesLineage[i][j])\n",
    "                            #print(speciesLineage[i][j], 'appended to char')\n",
    "                            match.append(0)\n",
    "                            parent.append('')\n",
    "                            #print('root appended as parent to', speciesLineage[i][j])\n",
    "                        else:\n",
    "                            char.append(speciesLineage[i][j])\n",
    "                            #print(speciesLineage[i][j], 'appended to char')\n",
    "                            match.append(0)\n",
    "                            parent.append(speciesLineage[i][j+1])\n",
    "        \n",
    "        if len(char) == len(parent) == len(match):\n",
    "            print(len(char), 'entries in total after adding parents to all.\\n')\n",
    "        else:\n",
    "            print('Something went horribly wrong with parent mapping. Visualization will probably not work :(')\n",
    "        \n",
    "        return char, parent, match\n",
    "    \n",
    "    def organizeData(self, char, parent, match):\n",
    "        \"\"\"\n",
    "        Organizes the data for plotly visualization.\n",
    "        \"\"\"\n",
    "        percentMatches = []\n",
    "        total = sum(self.count) # count or match? hmm\n",
    "        for i in match:\n",
    "            percent = round((i/total)*100, 2)\n",
    "            percentMatches.append(percent)\n",
    "            \n",
    "        plotData = dict(LCA = char,\n",
    "                        Parent = parent,\n",
    "                        PercentMatches = percentMatches)\n",
    "        return plotData\n",
    "    \n",
    "    def showList(self, n=25, minMatches = 5):\n",
    "        \"\"\"\n",
    "        Returns a list of the n taxons with the largest number of matches.\n",
    "        Adding percentMatches later\n",
    "        And maybe statistics from col 5\n",
    "        \"\"\"\n",
    "        char, parent, match = self.mapIDs(minMatches)\n",
    "        #plotData = self.organizeData(char, parent, match)\n",
    "        matchesAndLca = pd.DataFrame({'Matches' : match, 'LCA' : char})\n",
    "        matchesAndLcaSorted = matchesAndLca.sort_values('Matches', ascending=False)\n",
    "        matchesAndLcaSortedTopResults = matchesAndLcaSorted.head(n=n)\n",
    "        print('List of the top', n, 'taxons with most matches:\\n')\n",
    "        print(matchesAndLcaSortedTopResults.to_string(index=False))\n",
    "    \n",
    "    def showSunburst(self, minMatches = 5, width = 1100, height = 700, title = 'Sunburst chart'):\n",
    "        \"\"\"\n",
    "        Displays a sunburst diagram of the results filtered by minimum number of matches. \n",
    "        \"\"\"\n",
    "        char, parent, match = self.mapIDs(minMatches)\n",
    "        plotData = self.organizeData(char, parent, match)\n",
    "        fig = px.sunburst(plotData,\n",
    "                          names = 'LCA',\n",
    "                          parents = 'Parent',\n",
    "                          values = 'PercentMatches',\n",
    "                          color = 'PercentMatches',\n",
    "                          title = title,\n",
    "                          width = width,\n",
    "                          height = height,\n",
    "        )\n",
    "\n",
    "        fig.show()\n",
    "           \n",
    "    def showIcicle(self, minMatches = 5, width = 900, height = 2000, title = 'Icicle chart'):\n",
    "        \"\"\"\n",
    "        Displays an icicle chart of the results filtered by minimum number of matches.\n",
    "        \"\"\"\n",
    "        char, parent, match = self.mapIDs(minMatches)\n",
    "        plotData = self.organizeData(char, parent, match)\n",
    "        fig = px.icicle(plotData,\n",
    "                        names ='LCA',\n",
    "                        parents ='Parent',\n",
    "                        values = 'PercentMatches',\n",
    "                        color = 'PercentMatches',\n",
    "                        title = title,\n",
    "                        width = width,\n",
    "                        height = height,\n",
    "        )\n",
    "        fig.update_traces(root_color=\"lightgrey\")\n",
    "        fig.update_layout(margin = dict(t=50, l=25, r=25, b=25)) # might need fine-tuning depending on machine\n",
    "        fig.show()\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b05b2d72-8e56-4fdb-9421-55ded02ad7b5",
   "metadata": {},
   "source": [
    "#### Creek water"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d40f47a8-5f48-4370-a258-662f9564bc12",
   "metadata": {},
   "outputs": [],
   "source": [
    "creekWater = krakView('MYTEXT.kraken2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15e3683a-385e-4978-ba64-cc5695932a5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(creekWater.showFormat(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e923aaa-ed8c-4512-abdf-d47fd3d9dc4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "percentClassd = creekWater.percentClassified()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "548dc607-4b10-4f52-b921-ade37be3f7e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "nrOfUniques = creekWater.numberUniqueIDs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07d66a5e-6d04-489d-8d6d-b0a92ab34079",
   "metadata": {},
   "outputs": [],
   "source": [
    "creekWater.showList()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4687ffb-436c-4a2b-828d-ac09a96df806",
   "metadata": {},
   "outputs": [],
   "source": [
    "creekWater.showSunburst()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2999142b-823d-4dca-87fc-999b14668287",
   "metadata": {},
   "outputs": [],
   "source": [
    "creekWater.showIcicle()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0dfc659-162e-490a-8bea-3f55eadcd265",
   "metadata": {},
   "outputs": [],
   "source": [
    "creekWater.showList()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a97881dc-cbfa-407d-9c49-a4a83e3b2fe7",
   "metadata": {},
   "source": [
    "#### Raw sewage\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3da2b165-8376-4250-ba6f-cbb9fdff8c7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sewage = krakView('sewageTXT.kraken2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed097670-4b18-4d5f-8983-0ba7abceb674",
   "metadata": {},
   "outputs": [],
   "source": [
    "sewage.showList(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60aa412b-68aa-477b-a771-f366a8675b48",
   "metadata": {},
   "outputs": [],
   "source": [
    "sewage.showSunburst(minMatches=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d68a6dd4-55c2-4719-971f-5721a37542af",
   "metadata": {},
   "outputs": [],
   "source": [
    "sewage.showIcicle(minMatches = 1, height = 2800)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c2dd0bc-0264-44b5-9f53-d37c34dd647d",
   "metadata": {},
   "source": [
    "#### Fecal sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f85e48ea-c1ec-4e11-8f70-a26bbb1504ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "fecal = krakView('fecalTXT.kraken2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ebfd18c-50e1-48a7-b0ca-9b9c3a107f75",
   "metadata": {},
   "outputs": [],
   "source": [
    "fecal.showList(35)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79420d95-eeb8-4544-ba89-4671cc920e8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "fecal.showSunburst(minMatches=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e23ab95-b258-4d00-898a-2f97233bf9d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "fecal.showIcicle(4, height=5000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7cf6f28-9754-4672-98b0-abe71af06017",
   "metadata": {},
   "source": [
    "#### Endotracheal sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d27a0bfa-b92f-411e-8f20-d4cd25f1d49f",
   "metadata": {},
   "outputs": [],
   "source": [
    "endotrac = krakView('endotrTXT.kraken2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fee01155-44d9-49ce-9e7e-a6787c60f593",
   "metadata": {},
   "outputs": [],
   "source": [
    "endotrac.showList(minMatches=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a30b582-213d-4a0d-937b-90032e350bb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "endotrac.showIcicle(minMatches=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
